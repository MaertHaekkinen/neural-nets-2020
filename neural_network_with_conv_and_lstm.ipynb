{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "Imports data as numpy array (nr_of_sequences, 16, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing folder 0, number of images in that folder 16 \n",
      "total cumulative number of image sequences:  1\n",
      "processing folder 1, number of images in that folder 299 \n",
      "total cumulative number of image sequences:  285\n",
      "processing folder 2, number of images in that folder 44 \n",
      "total cumulative number of image sequences:  314\n",
      "processing folder 3, number of images in that folder 50 \n",
      "total cumulative number of image sequences:  349\n"
     ]
    }
   ],
   "source": [
    "from load_dataset_numpy import load_dataset_numpy\n",
    "\n",
    "sequence_limit = 15\n",
    "X_train, Y_train, X_train_flow_paths, X_train_warped_paths, X_train_diff_paths, X_test, Y_test, X_test_flow_paths, X_test_warped_paths, X_test_diff_paths, image_count = load_dataset_numpy(difficulty=\"All\", sequence_limit = sequence_limit + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape (349, 16, 128, 128, 3)\n",
      "number of sequences 349\n"
     ]
    }
   ],
   "source": [
    "print('output shape {}'.format(X_train.shape))\n",
    "print('number of sequences {}'.format(X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer structure\n",
    "\n",
    "<img src=\"images/layer_structure.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: if target is categorical use Dense(8) if target is binary use Dense(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_11 (TimeDis (None, 16, 61, 61, 96)    14208     \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 16, 30, 30, 96)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 16, 14, 14, 384)   332160    \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 16, 7, 7, 384)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 16, 7, 7, 512)     1769984   \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 16, 7, 7, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 16, 7, 7, 384)     1769856   \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 16, 3, 3, 384)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 16, 3456)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 16, 4096)          14159872  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               4457472   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 24,864,131\n",
      "Trainable params: 24,864,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Input, Conv2D, Dense, LSTM,MaxPooling2D , Flatten, TimeDistributed,Activation\n",
    "\n",
    "im_size = 128\n",
    "time_steps = 16 # len of image sequence\n",
    "channels = 3\n",
    "#input_shape=(5, 128, 128, 3)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(filters=96, kernel_size=7,  strides=2, padding='valid'), input_shape=(time_steps,im_size,im_size,channels))) # first input shape is the len of seq\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(filters=384, kernel_size=3,  strides=2, padding='valid')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(filters=512, kernel_size=3, padding='same')))\n",
    "model.add(TimeDistributed(Conv2D(filters=512, kernel_size=3, padding='same')))\n",
    "model.add(TimeDistributed(Conv2D(filters=384, kernel_size=3, padding='same')))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten())) #The Flatten layer is only needed because LSTM shape should have one dimension per input.\n",
    "model.add(TimeDistributed(Dense(4096)))\n",
    "model.add(LSTM(256, return_sequences=False)) #pole kindel return_sequence's, kui True, siis multiple outputs\n",
    "#When return_sequences=True, the output shape is (batch, timeSteps, outputFeatures)\n",
    "#When return_sequences=False, the output shape is (batch, outputFeatures)\n",
    "model.add((Dense(3))) # for categorical use Dense(8), for binary use Dense(3)\n",
    "model.add((Activation('softmax')))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLO', 'BOR', 'BOO', 'OOR', 'BLR', 'OOO', 'OLO', 'OLR'}\n",
      "categorical labels: \n",
      " [[0 0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#Encoding the labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "labels = set(['BOO', 'BLO', 'BOR', 'BLR', 'OLR', 'OLO', 'OOR', 'OOO'])\n",
    "print(labels)\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(list(labels))\n",
    "print('categorical labels: \\n', lb.transform(['BOO', 'BLO', 'BOR', 'BLR', 'OLR', 'OLO', 'OOR', 'OOO']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial labels: \n",
      " ['BOO', 'BLO', 'BOR', 'BLR', 'OLR', 'OLO', 'OOR', 'OOO']\n",
      "labels in binary: \n",
      " [[1 0 0]\n",
      " [1 1 0]\n",
      " [1 0 1]\n",
      " [1 1 1]\n",
      " [0 1 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=['B','L','R'])\n",
    "\n",
    "def labels_to_binary(ini_labels):\n",
    "    \"\"\"\n",
    "    Takes as input list of labels (e.g. ['BOO', 'BLO', 'BOR'])\n",
    "    Outputs numpy ndarray of the labels in binary (e.g. [[1 0 0] [1 1 0] [1 0 1])\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for label in ini_labels:\n",
    "        label_split = list(label) # ['BLO'] -> ['B','L','O']\n",
    "        labels.append(label_split) # [['B','L','O']]\n",
    "\n",
    "    return mlb.fit_transform(labels)\n",
    "\n",
    "\n",
    "ini_labels = ['BOO', 'BLO', 'BOR', 'BLR', 'OLR', 'OLO', 'OOR', 'OOO']\n",
    "print('initial labels: \\n', ini_labels)\n",
    "labels_binary = labels_to_binary(ini_labels)\n",
    "print('labels in binary: \\n', labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit generator\n",
    "TODO: implementeerida parameetri \"aug\" kasutus\n",
    "\n",
    "Source:https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from load_dataset_numpy import window\n",
    "\n",
    "# label_type: \"binary\" or \"categorical\"\n",
    "def png_image_generator(path, bs, mode=\"train\",difficulty=\"All\", sequence_limit=16, resize_dimension = 128, label_type = \"categorical\", aug=None):    \n",
    "    f = open(\"{0}/{1}.txt\".format(path, difficulty))\n",
    "\n",
    "    # loop indefinitely\n",
    "    while True:\n",
    "        # initialize our batches of images\n",
    "        image_count = 0\n",
    "        X_train = []\n",
    "        X_test = []\n",
    "        Y_train = []\n",
    "        Y_test = []\n",
    "        X_train_flow_paths = []\n",
    "        X_test_flow_paths = []\n",
    "        X_train_warped_paths = []\n",
    "        X_test_warped_paths = []\n",
    "        X_train_diff_paths = []\n",
    "        X_test_diff_paths = []\n",
    "\n",
    "        folder_count = 0\n",
    "        \n",
    "        content = f.readlines()\n",
    "        for folder in content:\n",
    "            # Load the data\n",
    "            folder_components = folder.split(\"_\")\n",
    "            folder_components[-1] = folder_components[-1][:-1]\n",
    "            base = str(\"_\".join(folder_components[:-2]))\n",
    "            folder = \"{0}/{1}/{2}\".format(path, base, (base + \"_\" + str(folder_components[-2])))\n",
    "            folder += \"/\" + (str(\"_\".join(folder_components)))\n",
    "            try:\n",
    "                os.makedirs(folder+\"/flow_fields\")\n",
    "            except: \n",
    "                pass\n",
    "            try:\n",
    "                os.makedirs(folder+\"/warped\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                os.makedirs(folder+\"/difference\")\n",
    "            except:\n",
    "                pass\n",
    "            folder += \"/light_mask\"\n",
    "            images = [folder + \"/\" + f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "            image_count += len(images)\n",
    "            img_list = [] #np.empty((16, 128,128,3)) # images from all the sequences\n",
    "\n",
    "            flow_path_list = []\n",
    "            warped_path_list = []\n",
    "            diff_path_list = []\n",
    "            im_seq_count = 0\n",
    "            print('\\n processing folder {0}, number of images in that folder {1} '.format(folder_count,len(images)))\n",
    "\n",
    "            # split the images into sequneces of length 16\n",
    "            #(e.g. folder contains 20 images, then first seq is 1-16, second seq 2-17, third seq 3-18 etc)\n",
    "            for each in window(images, 16):\n",
    "                img_seq_list = [] # only images from one 16 image sequence,  size will be (16, 128,128,3)\n",
    "                one_images_seq = np.array(each) # 1-16, 2-17, etc\n",
    "\n",
    "                # read each image to numpy sequence\n",
    "                for img in one_images_seq:\n",
    "                    img_load = load_img(img, target_size = (resize_dimension,resize_dimension))\n",
    "                    img_array = img_to_array(img_load)\n",
    "                    img_seq_list.append(img_array)\n",
    "\n",
    "                    flow_path_list.append(img.replace('/light_mask','/flow_fields'))\n",
    "                    warped_path_list.append(img.replace('/light_mask','warped'))\n",
    "                    diff_path_list.append(img.replace('light_mask','difference'))\n",
    "\n",
    "                if(\"test-\" in folder):\n",
    "                    X_test.append(np.asarray(img_seq_list))\n",
    "                    Y_test.append(folder_components[-2])     \n",
    "                    X_test_flow_paths.append(flow_path_list)\n",
    "                    X_test_warped_paths.append(warped_path_list)\n",
    "                    X_test_diff_paths.append(diff_path_list)\n",
    "                    if (len(X_test) == bs):\n",
    "                        if label_type == \"categorical\":\n",
    "                            Y_test = lb.transform(np.array(Y_test))\n",
    "                        elif label_type == \"binary\": # label type is binary\n",
    "                            Y_test = labels_to_binary(Y_test)\n",
    "                        else:\n",
    "                            print('Invalid label type!')\n",
    "                        yield np.asarray(X_test), np.asarray(Y_test)\n",
    "                        X_test=[]\n",
    "                        Y_test=[]\n",
    "                else:\n",
    "                    X_train.append(np.asarray(img_seq_list)) \n",
    "                    Y_train.append(folder_components[-2])\n",
    "                    X_train_flow_paths.append(flow_path_list)\n",
    "                    X_train_warped_paths.append(warped_path_list)\n",
    "                    X_train_diff_paths.append(diff_path_list)\n",
    "                    if (len(X_train) == bs):                        \n",
    "                        if label_type == \"categorical\":\n",
    "                            Y_train = lb.transform(np.array(Y_train))\n",
    "                        elif label_type == \"binary\":\n",
    "                            Y_train = labels_to_binary(Y_train)\n",
    "                        else:\n",
    "                            print('Invalid label type!')\n",
    "                        yield np.asarray(X_train), np.asarray(Y_train)\n",
    "                        X_train=[]\n",
    "                        Y_train=[]\n",
    "\n",
    "            folder_count +=1\n",
    "            #print('total cumulative number of image sequences: ', np.asarray(X_train).shape[0])\n",
    "        \n",
    "        #print('have reached the batch sized', np.asarray(X_train).shape[0], '\\n\\n')\n",
    "            # if the data augmentation object is not None, apply it\n",
    "        #if aug is not None:\n",
    "        #    (images, labels) = next(aug.flow(np.array(images),\n",
    "        #        labels, batch_size=bs))\n",
    "        # yield the batch to the calling function\n",
    "        \n",
    "        # võib muuta X_train_flow, X_train_wraped etc\n",
    "        #yield np.asarray(X_train), np.asarray(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* hetkel ei tea, mitu train image sequencit ja test image sequencit on. Vaja see leida, hetkel suvalised numbrid NUM_TRAIN_IMAGES ja NUM_TEST_IMAGES all.\n",
    "* implementeerida ImageDataGenerator kasutus (selle põhjal: https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "label_type = \"binary\" #\"categorical\"\n",
    "# initialize the number of epochs to train for and batch size\n",
    "NUM_EPOCHS = 2\n",
    "BS = 8 # TODO: standard on vist 32 või 64?\n",
    "\n",
    "# initialize the total number of training and testing image\n",
    "# TODO:  hetkel suvalised numbrid\n",
    "NUM_TRAIN_IMAGES = 500\n",
    "NUM_TEST_IMAGES = 500\n",
    "\n",
    "# TODO: hetkel pole kasutuses\n",
    "# construct the training image generator for data augmentation\n",
    "# image data augmentation object will randomly rotate, flip, shear, etc. our training images.\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "    width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "trainGen = png_image_generator(\"./rear_signal_dataset\", bs=BS, mode=\"train\", difficulty=\"Easy\", label_type = label_type, aug=None)\n",
    "testGen = png_image_generator(\"./rear_signal_dataset\", bs=BS, mode=\"test\", difficulty=\"Easy\", label_type = label_type, aug=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: if target is categorical use categorical_crossentropy, if target is binary use binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training w/ generator...\n",
      "Epoch 1/2\n",
      "\n",
      " processing folder 0, number of images in that folder 16 \n",
      "\n",
      " processing folder 0, number of images in that folder 16 \n",
      "\n",
      " processing folder 1, number of images in that folder 299 \n",
      "\n",
      " processing folder 1, number of images in that folder 299 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anneott/miniconda3/envs/stacc/lib/python3.6/site-packages/sklearn/preprocessing/label.py:951: UserWarning: unknown class(es) ['O'] will be ignored\n",
      "  .format(sorted(unknown, key=str)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/62 [==========>...................] - ETA: 3:34 - loss: 0.2741 - accuracy: 0.9271\n",
      " processing folder 2, number of images in that folder 44 \n",
      "28/62 [============>.................] - ETA: 3:07 - loss: 0.2466 - accuracy: 0.9375\n",
      " processing folder 3, number of images in that folder 50 \n",
      "32/62 [==============>...............] - ETA: 2:42 - loss: 0.2232 - accuracy: 0.9453\n",
      " processing folder 4, number of images in that folder 58 \n",
      "38/62 [=================>............] - ETA: 2:07 - loss: 0.3181 - accuracy: 0.9123\n",
      " processing folder 5, number of images in that folder 47 \n",
      "42/62 [===================>..........] - ETA: 1:45 - loss: 0.3945 - accuracy: 0.8790\n",
      " processing folder 6, number of images in that folder 119 \n",
      "55/62 [=========================>....] - ETA: 36s - loss: 0.4442 - accuracy: 0.8288\n",
      " processing folder 7, number of images in that folder 21 \n",
      "\n",
      " processing folder 8, number of images in that folder 28 \n",
      "57/62 [==========================>...] - ETA: 25s - loss: 0.4448 - accuracy: 0.8231\n",
      " processing folder 9, number of images in that folder 71 \n",
      "61/62 [============================>.] - ETA: 5s - loss: 0.4444 - accuracy: 0.8128 \n",
      " processing folder 2, number of images in that folder 44 \n",
      "\n",
      " processing folder 3, number of images in that folder 50 \n",
      "\n",
      " processing folder 4, number of images in that folder 58 \n",
      "\n",
      " processing folder 5, number of images in that folder 47 \n",
      "\n",
      " processing folder 6, number of images in that folder 119 \n",
      "\n",
      " processing folder 7, number of images in that folder 21 \n",
      "\n",
      " processing folder 8, number of images in that folder 28 \n",
      "\n",
      " processing folder 9, number of images in that folder 71 \n",
      "62/62 [==============================] - 418s 7s/step - loss: 0.4442 - accuracy: 0.8105 - val_loss: 0.4237 - val_accuracy: 0.7419\n",
      "Epoch 2/2\n",
      " 2/62 [..............................] - ETA: 4:36 - loss: 0.4224 - accuracy: 1.0000\n",
      " processing folder 10, number of images in that folder 47 \n",
      " 6/62 [=>............................] - ETA: 4:19 - loss: 0.4197 - accuracy: 1.0000\n",
      " processing folder 11, number of images in that folder 82 \n",
      "14/62 [=====>........................] - ETA: 3:50 - loss: 0.4157 - accuracy: 1.0000\n",
      " processing folder 12, number of images in that folder 82 \n",
      "23/62 [==========>...................] - ETA: 3:07 - loss: 0.4133 - accuracy: 1.0000\n",
      " processing folder 13, number of images in that folder 190 \n",
      "45/62 [====================>.........] - ETA: 1:21 - loss: 0.4105 - accuracy: 1.0000\n",
      " processing folder 14, number of images in that folder 53 \n",
      "49/62 [======================>.......] - ETA: 1:02 - loss: 0.4102 - accuracy: 1.0000\n",
      " processing folder 15, number of images in that folder 299 \n",
      "61/62 [============================>.] - ETA: 4s - loss: 0.4114 - accuracy: 0.9973\n",
      " processing folder 10, number of images in that folder 47 \n",
      "\n",
      " processing folder 11, number of images in that folder 82 \n",
      "\n",
      " processing folder 12, number of images in that folder 82 \n",
      "\n",
      " processing folder 13, number of images in that folder 190 \n",
      "\n",
      " processing folder 14, number of images in that folder 53 \n",
      "\n",
      " processing folder 15, number of images in that folder 299 \n",
      "62/62 [==============================] - 396s 6s/step - loss: 0.4190 - accuracy: 0.9866 - val_loss: 0.8704 - val_accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "#model = MiniVGGNet.build(64, 64, 3, len(lb.classes_))\n",
    "#opt = SGD(lr=1e-2, momentum=0.9, decay=1e-2 / NUM_EPOCHS)\n",
    "\n",
    "#model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',metrics=[\"accuracy\"])\n",
    "if label_type == 'binary':\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "elif label_type == 'categorical':\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam',metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training w/ generator...\")\n",
    "H = model.fit(\n",
    "    x=trainGen,\n",
    "    steps_per_epoch=NUM_TRAIN_IMAGES // BS,\n",
    "    validation_data=testGen,\n",
    "    validation_steps=NUM_TEST_IMAGES // BS,\n",
    "    epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
